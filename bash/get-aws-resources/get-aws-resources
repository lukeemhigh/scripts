#!/usr/bin/env bash
#
# Simple script to generate an xlsx file containing in-use aws resources with their respective tags,
# grouped by region and service type.
#
# Author: Luca Giugliardi
# Email: <luca.giugliardi@gmail.com>

# ----------------------------- Shell Options ----------------------------

set -o pipefail

# -------------------------------- Optargs -------------------------------

TEMP=$(getopt -o p:j: --long profile:,jobs: -n 'get-aws-resources' -- "$@")

if [ $? -ne 0 ]; then
  echo "usage: $0 [--profile | -p ] [AWS PROFILE] [--jobs | -j] [CONCURRENT JOB NUMBER]"
  exit 1
fi

eval set -- "$TEMP"

while true; do
  case "$1" in
    -p | --profile)
      profile="$2"
      shift 2
      ;;
    -j | --jobs)
      jobs="$2"
      shift 2
      ;;
    --)
      shift
      break
      ;;
    *)
      echo "usage: $0 [--profile | -p ] [AWS PROFILE] [--jobs | -j] [CONCURRENT JOB NUMBER]"
      exit 1
      ;;
  esac
done

# ------------------------------- Functions ------------------------------

get_lib_path() {
  local lib_path
  lib_path=$(cd "$(dirname "$0")" && echo "${PWD}" | sed 's/\/[^/]*$/\/lib/')
  echo "${lib_path}"
}

check_resources() {
  local region="$1"
  local service="$2"
  local profile="$3"
  local date="$4"
  local output_path="$5"
  local filename

  print_color "blue" "$(date '+%Y-%m-%d %H:%M:%S') [INFO]: Checking services in $region..."

  filename="${region}-${service}.csv"

  aws --profile "${profile}" resourcegroupstaggingapi get-resources \
    --resource-type-filters "$service" \
    --region="$region" \
    --output json 2>/dev/null |
    jq -r '.ResourceTagMappingList[] | . as $e | .Tags[] | [$e.ResourceARN, .Key, .Value] | @csv' \
      >>"${output_path}/data/${filename}"

  if [ ! -s "${output_path}/data/${filename}" ]; then
    rm -f "${output_path}/data/${filename}"
    print_color "green" "$(date '+%Y-%m-%d %H:%M:%S') [DEBUG] No $service services found in $region"
  else
    sed -i -r "s/^/\"$region\",\"$service\",/g" "${output_path}/data/${filename}"
    print_color "blue" "$(date '+%Y-%m-%d %H:%M:%S') [INFO] Check completed, data witten into ${output_path}/data/${filename}"
  fi
}

main() {
  local region_list=(
    "us-east-2"
    "us-east-1"
    "us-west-1"
    "us-west-2"
    "af-south-1"
    "ap-east-1"
    "ap-southeast-3"
    "ap-south-1"
    "ap-northeast-3"
    "ap-northeast-2"
    "ap-southeast-1"
    "ap-southeast-2"
    "ap-northeast-1"
    "ca-central-1"
    "eu-central-1"
    "eu-west-1"
    "eu-west-2"
    "eu-south-1"
    "eu-west-3"
    "eu-north-1"
    "me-south-1"
    "me-central-1"
    "sa-east-1"
  )

  local services_list=(
    "amplify"
    "cloudfront"
    "cloudwatch"
    "cognito"
    "dynamodb"
    "ebs"
    "ec2"
    "ecs"
    "eks"
    "elasticache"
    "elb"
    "iam"
    "lambda"
    "rds"
    "route53"
    "s3"
    "sns"
    "sqs"
  )

  local date
  local output_path
  local filename
  local profile="$1"

  date=$(date +%F_%T)
  output_path="${HOME}/tmp/get-aws-resources-${date}"

  if [[ -z $profile ]]; then
    profile=$(get_aws_profile)
  fi

  mkdir -p "${output_path}/data"
  mkdir -p "${output_path}/output"

  parallel --ungroup --jobs "${jobs}" check_resources ::: "${region_list[@]}" ::: "${services_list[@]}" ::: "${profile}" ::: "${date}" ::: "${output_path}"

  print_color "blue" "$(date '+%Y-%m-%d %H:%M:%S') [INFO]: Done writing csv files. Launching csv-import.py.."

  conda_activate get-aws-resources

  ./csv-import.py --directory "$output_path"
}

# --------------------------- Import Functions ---------------------------

lib_path=$(get_lib_path)

# shellcheck source=/dev/null
source "${lib_path}/print-color.sh"

# shellcheck source=/dev/null
source "${lib_path}/check-utils.sh"

# shellcheck source=/dev/null
source "${lib_path}/get-aws-profile.sh"

# shellcheck source=/dev/null
source "${lib_path}/conda-activate.sh"

# -------------------------- Writing .csv files --------------------------

main "${profile}"
